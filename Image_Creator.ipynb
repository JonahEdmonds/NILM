{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonahEdmonds/NILM/blob/main/Image_Creator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQRG_YhHd5Ze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "3b280f30-9224-4f1e-86d1-dc6db9c5e020"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/MyDrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c0fc2c3766a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mnormed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must be in a directory that exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m   \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGKILL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must be in a directory that exists"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL0DftNYjAQx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pylab\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "import PIL\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "g5h3QYGwDJY7",
        "outputId": "43c9c9f2-b06e-4e6c-c5a5-fdf22381654b"
      },
      "source": [
        "file_path2 = '/content/drive/MyDrive/Smart_Meters/house_1_apps/Fridge.dat'\n",
        "file_path = '/content/drive/MyDrive/Smart_Meters/house_5_apps/TV.dat'\n",
        "file_path_aggregate = '/content/drive/MyDrive/Smart_Meters/house_1_apps/Agg.dat'\n",
        "\n",
        "s = 1\n",
        "Period = 5\n",
        "size = (24, 720)\n",
        "\n",
        "NILMHeatmapMulti(file_path_aggregate, file_path,file_path2, '', s, Period, size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-80a9e3ce3c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mNILMHeatmapMulti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path_aggregate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_path2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'NILMHeatmapMulti' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79Fr7k9xzh-2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "cb2a8c4f-7f91-44d5-dcc4-ea2b0ac83609"
      },
      "source": [
        "def NILMHeatmapMulti(Agg_file, App_file, App_file2, App, start, Period = 5, Size = None):\n",
        "  TotalTime = size[0] * size[1]\n",
        "  table = pd.read_table(App_file,sep=\"\\s+\",names=['t','PR'])\n",
        "  table2 = pd.read_table(App_file2,sep=\"\\s+\",names=['t','PR'])\n",
        "  table_agg = pd.read_table(Agg_file ,sep=\"\\s+\",names=['t','PR']) \n",
        "  # Read Files into tables\n",
        "  \n",
        "  data = table.to_numpy()\n",
        "  data2 = table2.to_numpy()\n",
        "  data_agg = table_agg.to_numpy() \n",
        "  # Change tables to NP arrays\n",
        "\n",
        "  data[:,0] = data[:,0] - data_agg[:,0].min()\n",
        "  data2[:,0] = data2[:,0] - data_agg[:,0].min()\n",
        "  data_agg[:,0] = data_agg[:,0] - data_agg[:,0].min() \n",
        "  # Standardising time \n",
        "\n",
        "  index = data[:,1]  > 10\n",
        "  index2 = data2[:,1] > 10\n",
        "  data = data[index]\n",
        "  data2 = data2[index2]\n",
        "\n",
        "  window_start = start * 86400 \n",
        "  window_stop = window_start + TotalTime\n",
        "  # Conversion of days to seconds\n",
        "  \n",
        "  ind_agg = (data_agg[:,0] >= (window_start)) & (data_agg[:,0] < (window_stop)) \n",
        "  ind = (data[:,0] >= (window_start)) & (data[:,0] < (window_stop)) \n",
        "  ind2 = (data2[:,0] >= (window_start)) & (data2[:,0] < (window_stop)) # Obtaining values for specified windows \n",
        "\n",
        "  data_agg_test = data_agg[ind_agg]\n",
        "  data_test = data[ind]\n",
        "  data_test2 = data2[ind2] # Seperating the chosen data\n",
        "\n",
        "  \n",
        "  if len(data_agg_test) < 1:\n",
        "    print('No aggregated data ')\n",
        "  else:\n",
        "    day_data = np.zeros(int(TotalTime))\n",
        "    day_data2 = np.zeros(int(TotalTime))\n",
        "    day_data_none = np.zeros(int(TotalTime))\n",
        "    day_data_agg = np.zeros(int(TotalTime))\n",
        "    counter = 0\n",
        "    counter2 = 0\n",
        "    counter_none = 0\n",
        "    for i in range(TotalTime):\n",
        "      idx_agg = (data_agg_test[:,0] >= (int(window_start/Period) + i) & (data_agg_test[:,0] < (int(window_start/Period) + i + 1)\n",
        "      idx = (data_test[:,0] >= (int(window_start/Period) + i)) & (data_test[:,0] < (int(window_start/Period) * 2))\n",
        "      idx2 = (data_test2[:,0] >= (int(window_start/Period) + i) & (data_test2[:,0] < (int(window_start/Period) * 2))\n",
        "       # Window start + time in seconds\n",
        "\n",
        "      day_data_agg[i] = np.mean(data_agg_test[idx_agg,1])\n",
        "      \n",
        "      if np.isnan(np.mean(data_test[idx,1])) == True:\n",
        "        day_data[i] = np.mean(data_agg_test[idx_agg,1]) # removing NaN\n",
        "        counter += 1\n",
        "\n",
        "      else:\n",
        "        day_data[i] = np.mean(data_agg_test[idx_agg,1]) - np.mean(data_test[idx,1])\n",
        "\n",
        "      if np.isnan(np.mean(data_test2[idx2,1])) == True: \n",
        "        day_data2[i] = np.mean(data_agg_test[idx_agg,1]) # Removing NaN\n",
        "        counter2 += 1\n",
        "\n",
        "      else:\n",
        "        day_data2[i] = np.mean(data_agg_test[idx_agg,1]) - np.mean(data_test2[idx2,1])\n",
        "\n",
        "      if (np.isnan(np.mean(data_test[idx,1])) == True) & (np.isnan(np.mean(data_test2[idx2,1])) == True):\n",
        "        day_data_none[i]  = np.mean(data_agg_test[idx_agg,1]) #Removing NaN\n",
        "        counter_none += 1\n",
        "\n",
        "      else:\n",
        "        day_data_none[i] = np.mean(data_agg_test[idx_agg,1]) - np.mean(data_test[idx,1]) - np.mean(data_test2[idx2,1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    heatmap = np.transpose(day_data.reshape(size))\n",
        "    heatmap2 = np.transpose(day_data2.reshape(size))\n",
        "    heatmap_none = np.transpose(day_data_none.reshape(size))\n",
        "    heatmap_agg = np.transpose(day_data_agg.reshape(size)) \n",
        "    # Reszing data to be hourly for each day in 5 second intervals \n",
        "\n",
        "    i1 = np.isnan(heatmap) == False\n",
        "    i2 = np.isnan(heatmap2) == False\n",
        "    i_none = np.isnan(heatmap_none) == False\n",
        "    i_agg = np.isnan(heatmap_agg) == False\n",
        "\n",
        "\n",
        "    heatmap = (heatmap - np.mean(heatmap[i1]))/(np.std(heatmap[i1]))\n",
        "    heatmap2 = (heatmap2 - np.mean(heatmap2[i2]))/(np.std(heatmap2[i2]))\n",
        "    heatmap_none = (heatmap_none - np.mean(heatmap_none[i_none]))/(np.std(heatmap_none[i_none]))\n",
        "    heatmap_agg = (heatmap_agg - np.mean(heatmap_agg[i_agg]))/(np.std(heatmap_agg[i_agg]))\n",
        "\n",
        "    if counter == TotalTime & counter2 == TotalTime:\n",
        "      plt.figure()\n",
        "      plt.title('Aggregated data for day ' + str(start + 1))\n",
        "      plt.xlabel('Hours')\n",
        "      plt.ylabel('5 Seconds')\n",
        "      plt.axis('on')\n",
        "      sns.heatmap(heatmap_agg,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar = True)\n",
        "      plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/Multiclass_test/Class_None/5Day'+ str(start + 1))\n",
        "      \n",
        "    elif counter == TotalTime:\n",
        "      plt.figure()\n",
        "      plt.title('Aggregated data for day ' + str(start + 1))\n",
        "      plt.xlabel('Hours')\n",
        "      plt.ylabel('5 Seconds')\n",
        "      plt.axis('on')\n",
        "      sns.heatmap(heatmap_agg,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar = True)\n",
        "      plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/Multiclass_test/Class_No_1/5Day'+ str(start + 1))\n",
        "\n",
        "      plt.figure()\n",
        "      plt.title('Aggregated data for day ' + str(start + 1))\n",
        "      plt.xlabel('Hours')\n",
        "      plt.ylabel('5 Seconds')\n",
        "      plt.axis('on')\n",
        "      sns.heatmap(heatmap2,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar = False)\n",
        "      plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/Multiclass_test/Class_None/5Day'+ str(start + 1))\n",
        "\n",
        "    elif counter2 == TotalTime:\n",
        "      plt.figure()\n",
        "      plt.title('Aggregated data for day ' + str(start + 1))\n",
        "      plt.xlabel('Hours')\n",
        "      plt.ylabel('5 Seconds')\n",
        "      plt.axis('on')\n",
        "      sns.heatmap(heatmap_agg,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar = True)\n",
        "      plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/Multiclass_test/Class_No_2/5Day'+ str(start + 1))\n",
        "\n",
        "      plt.figure()\n",
        "      plt.title('Aggregated data for day ' + str(start + 1))\n",
        "      plt.xlabel('Hours')\n",
        "      plt.ylabel('5 Seconds')\n",
        "      plt.axis('on')\n",
        "      sns.heatmap(heatmap,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar = False)\n",
        "      plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/Multiclass_test/Class_None/5Day'+ str(start + 1))\n",
        "      plt.pyplot.close()\n",
        "\n",
        "    else:\n",
        "      plt.figure(j)\n",
        "      plt.title('Aggregated data for day ' + str(start + 1))\n",
        "      plt.xlabel('Hours')\n",
        "      plt.ylabel('5 Seconds')\n",
        "      plt.axis('on')\n",
        "      sns.heatmap(heatmap_agg,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar = True)\n",
        "      plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/Multiclass_test/Class_Agg/5Day'+ str(start + 1))\n",
        "\n",
        "      plt.figure()\n",
        "      plt.title('Aggregated data for day ' + str(start + 1))\n",
        "      plt.xlabel('Hours')\n",
        "      plt.ylabel('5 Seconds')\n",
        "      plt.axis('on')\n",
        "      sns.heatmap(heatmap,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar = False)\n",
        "      plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/Multiclass_test/Class_No_2/5Day'+ str(start + 1))\n",
        "\n",
        "      plt.figure()\n",
        "      plt.title('Aggregated data for day ' + str(start + 1))\n",
        "      plt.xlabel('Hours')\n",
        "      plt.ylabel('5 Seconds')\n",
        "      plt.axis('on')\n",
        "      sns.heatmap(heatmap2,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar = False)\n",
        "      plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/Multiclass_test/Class_No_1/5Day'+ str(start + 1))\n",
        "\n",
        "      plt.figure()\n",
        "      plt.title('Aggregated data for day ' + str(start + 1))\n",
        "      plt.xlabel('Hours')\n",
        "      plt.ylabel('Seconds')\n",
        "      plt.axis('on')\n",
        "      sns.heatmap(heatmap_none,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar = False)\n",
        "      plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/Multiclass_test/Class_None/5Day'+ str(start + 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-f64bd1d816db>\"\u001b[0;36m, line \u001b[0;32m48\u001b[0m\n\u001b[0;31m    idx = (data_test[:,0] >= (int(window_start/Period) + i)) & (data_test[:,0] < (int(window_start/Period) * 2))\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIsX3wY09NZR"
      },
      "source": [
        "NILMHeatmapMulti(file_path_aggregate, file_path, file_path2, 'dishwasher', 368,370)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4VZOOqch-WZ"
      },
      "source": [
        "  table1 = pd.read_table(file_path,sep=\"\\s+\",names=['t','PR'])\n",
        "  table_agg1 = pd.read_table(file_path_aggregate ,sep=\"\\s+\",names=['t','PR'])\n",
        "  \n",
        "  data1 = table1.to_numpy()\n",
        "  data_agg1 = table_agg1.to_numpy()\n",
        "\n",
        "  data1[:,0] = data1[:,0] - data_agg1[:,0].min()\n",
        "  data_agg1[:,0] = data_agg1[:,0] - data_agg1[:,0].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPORyZAdiwwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7022ab72-880d-430d-fd24-d9854970d9ff"
      },
      "source": [
        "  Agg_days = (data_agg1[-1,0] - data_agg1[0,0]) / (60*60*24)     #Total Num of days for agg\n",
        "  App_days = (data1[-1,0] - data1[0,0]) / (60 * 60 * 24)     #Total Num of days for app\n",
        "  Day_start = (data1[0,0] - data_agg1[0,0]) / (60 * 60 *24)     #Day that appliance data starts\n",
        "  Total_days = Agg_days - Day_start # Days that are tehrefore available\n",
        "  Train_days = Total_days * 0.8 # No of Training Days\n",
        "  Val_days = Total_days * 0.2 # No of Validation Days\n",
        "  print(Agg_days)\n",
        "  print(App_days)\n",
        "  print(Day_start)\n",
        "  print(Total_days)\n",
        "  print(Train_days)\n",
        "  print(Val_days)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1628.7947337962962\n",
            "137.06417824074074\n",
            "596.7469560185185\n",
            "1032.0477777777778\n",
            "825.6382222222223\n",
            "206.40955555555558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU0hedL9tA-v"
      },
      "source": [
        "NILMHeatmap(file_path_aggregate, file_path, 'TV', 0,125)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__G9WHY3qw61"
      },
      "source": [
        "def NILMHeatmap(Agg_file, App_file, App, start, stop):\n",
        "\n",
        "  table = pd.read_table(App_file,sep=\"\\s+\",names=['t','PR'])\n",
        "  table_agg = pd.read_table(Agg_file ,sep=\"\\s+\",names=['t','PR'])\n",
        "  \n",
        "  data = table.to_numpy()\n",
        "  data_agg = table_agg.to_numpy()\n",
        "\n",
        "  data[:,0] = data[:,0] - data_agg[:,0].min()\n",
        "  data_agg[:,0] = data_agg[:,0] - data_agg[:,0].min()\n",
        "\n",
        "  index = data[:,1]  > 10\n",
        "  data = data[index]\n",
        "  # print(data[:,1])\n",
        "\n",
        "  # data[:,1] = stats.zscore(data[:,1])\n",
        "  # data_agg[:,1] = stats.zscore(data_agg[:,1])\n",
        "\n",
        "  # print(data_agg[:,1].max())\n",
        "  # print(data[:,1].max())\n",
        "\n",
        "\n",
        "  # z_score = stats.zscore(data[:,1])\n",
        "  # ind = z_score < 4\n",
        "  # data = data[ind]\n",
        "\n",
        "  # z_score_agg = stats.zscore(data_agg[:,1])\n",
        "  # ind_agg = z_score_agg < 4\n",
        "  # data_agg = data_agg[ind_agg]\n",
        "\n",
        "  window_start = start * 86400\n",
        "  window_stop = stop * 86400\n",
        "  ind_agg = (data_agg[:,0] >= (window_start)) & (data_agg[:,0] < (window_stop)) \n",
        "  ind = (data[:,0] >= (window_start)) & (data[:,0] < (window_stop)) \n",
        "\n",
        "  data_agg_test = data_agg[ind_agg] \n",
        "  data_test = data[ind]\n",
        "\n",
        "  \n",
        "  if len(data_agg_test) < 1:\n",
        "    print('No aggregated data ')\n",
        "  else:\n",
        "\n",
        "  # m = round((data_agg_test[:,0].max() - data_agg_test[:,0].min())/86400)\n",
        " \n",
        "  # print(data_agg_test[:,0].max())\n",
        "  # print(data_agg_test[:,0].min())\n",
        "    m = stop-start\n",
        "\n",
        "    for j in range(m):\n",
        "      day_data = np.zeros(17280)\n",
        "      day_data_agg = np.zeros(17280)\n",
        "      counter = 0\n",
        "      for i in range(17280):\n",
        "        idx_agg = (data_agg_test[:,0] >= (window_start) + (j*86400) + (i*5)) & (data_agg_test[:,0] < (window_start) + (j*86400)+((i+1)*5))\n",
        "        idx = (data_test[:,0] >= (window_start) +  (j*86400)+(i*5)) & (data_test[:,0] < (window_start) + (j*86400)+((i+1)*5))\n",
        "        \n",
        "\n",
        "        day_data_agg[i] = np.mean(data_agg_test[idx_agg,1])\n",
        "        \n",
        "        if np.isnan(np.mean(data_test[idx,1])) == True:\n",
        "          day_data[i] = np.mean(data_agg_test[idx_agg,1])\n",
        "          counter += 1\n",
        "\n",
        "        else:\n",
        "          day_data[i] = np.mean(data_agg_test[idx_agg,1]) - np.mean(data_test[idx,1])\n",
        "\n",
        "\n",
        "      heatmap = np.transpose(day_data.reshape(24,720))\n",
        "      heatmap_agg = np.transpose(day_data_agg.reshape(24,720))\n",
        "\n",
        "      i = np.isnan(heatmap) == False\n",
        "      i_agg = np.isnan(heatmap_agg) == False\n",
        "\n",
        "\n",
        "      heatmap = (heatmap - np.mean(heatmap[i]))/(np.std(heatmap[i]))\n",
        "      heatmap_agg = (heatmap_agg - np.mean(heatmap_agg[i_agg]))/(np.std(heatmap_agg[i_agg]))\n",
        "      # print(heatmap_agg[i].max())\n",
        "      # print(heatmap[i].max())\n",
        "\n",
        "      if counter == 17280:\n",
        "        \n",
        "        plt.figure\n",
        "        plt.title('Aggregated data for day ' + str(start + j + 1))\n",
        "        plt.xlabel('Hours')\n",
        "        plt.ylabel('Seconds')\n",
        "        plt.axis('off')\n",
        "        sns.heatmap(heatmap_agg,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar = False)\n",
        "        plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/TV_test/Class_No_App-TV/5Day'+ str(start + j + 1))\n",
        "        #plt.show()\n",
        "\n",
        "      else:\n",
        "\n",
        "        plt.figure\n",
        "        plt.title('Aggregated data for day ' + str(start + j + 1))\n",
        "\n",
        "        plt.axis('off')\n",
        "        sns.heatmap(heatmap_agg,vmin=-5,vmax=10,cmap='RdYlBu_r',cbar= False)\n",
        "        plt.xlabel('Hours')\n",
        "        plt.ylabel('Seconds')\n",
        "        plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/TV_test/Class_App-TV/5Day'+ str(start + j + 1))        \n",
        "        #plt.show()\n",
        "\n",
        "        plt.figure\n",
        "        plt.title('Aggregated data for day ' + str(start + j + 1) + ' minus the ' + App)\n",
        "\n",
        "       # plt.axis('off')\n",
        "        sns.heatmap(heatmap,vmin=-5,vmax=10,cmap='RdYlBu_r', cbar=False)\n",
        "        plt.xlabel(\"Hours\")\n",
        "        plt.ylabel(\"Seconds\")\n",
        "        plt.savefig('/content/drive/MyDrive/Smart_Meters/Final_sets/TV_test/Class_No_App-TV/5Day'+ str(start + j + 1))\n",
        "        #plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giGXBmjMiegC"
      },
      "source": [
        "s = 100\n",
        "e = 110\n",
        "\n",
        "for i in range(3):\n",
        "  NILMHeatmap(file_path_aggregate, file_path, 'TV', s,e)\n",
        "  s += 10\n",
        "  e += 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WF8vJPWvOnv"
      },
      "source": [
        "a = np.random.rand(10)*10\n",
        "print(a)\n",
        "a = (a - np.mean(a))/np.std(a)\n",
        "\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjRLH97gDfET"
      },
      "source": [
        "TimeSeries(file_path_aggregate, file_path, 'Refrigerator', 124,125)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGUVM1_gBh4J"
      },
      "source": [
        "def TimeSeries(Agg_file, App_file, App, start, stop):\n",
        "  table = pd.read_table(App_file,sep=\"\\s+\",names=['t','PR'])\n",
        "  table_agg = pd.read_table(Agg_file ,sep=\"\\s+\",names=['t','PR'])\n",
        "  \n",
        "  data = table.to_numpy()\n",
        "  data_agg = table_agg.to_numpy()\n",
        "\n",
        "  data[:,0] = data[:,0] - data_agg[:,0].min()\n",
        "  data_agg[:,0] = data_agg[:,0] - data_agg[:,0].min()\n",
        "\n",
        "  window_start = start * 86400\n",
        "  window_stop = stop * 86400\n",
        "  ind_agg = (data_agg[:,0] >= (window_start)) & (data_agg[:,0] < (window_stop)) \n",
        "  ind = (data[:,0] >= (window_start)) & (data[:,0] < (window_stop)) \n",
        "\n",
        "  data_agg_test = data_agg[ind_agg] \n",
        "  data_test = data[ind]\n",
        "\n",
        "\n",
        "  if len(data_agg_test) < 1:\n",
        "    print('No aggregated data ')\n",
        "  else:\n",
        "    m = stop -start\n",
        "    for j in range(m):\n",
        "      ind_agg = (data_agg_test[:,0] >= (window_start) + (j*86400)) & (data_agg_test[:,0] < (window_start) + ((j+1)*86400))\n",
        "      ind = (data_test[:,0] >= (window_start) + (j*86400)) & (data_test[:,0] < (window_start) + ((j+1)*86400))\n",
        "      \n",
        "      val_agg = data_agg_test[ind_agg]\n",
        "      val_agg[:,0] = val_agg[:,0] - val_agg[0,0]\n",
        "      val = data_test[ind]\n",
        "      val[:,0] = val[:,0] - val[0,0]\n",
        "      plt.figure\n",
        "      plt.title('Time series representation of UK Dale dataset')\n",
        "      plt.plot(val_agg[:,0],val_agg[:,1],label = 'Aggregated Data')\n",
        "      plt.plot(val[:,0],val[:,1], label = App + ' Data')\n",
        "      plt.xlabel('Time (s)')\n",
        "      plt.ylabel('Power reading (W)')\n",
        "      plt.ylim(0,2000)\n",
        "      plt.legend()\n",
        "      plt.savefig('/content/drive/MyDrive/Smart_Meters/Report Image/TS' + App + str(start + j + 1) + '.pdf')\n",
        "      plt.show()\n",
        "      print(val_agg[-1,0])\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9E71-IxrOrt"
      },
      "source": [
        "table = pd.read_table(file_path,sep=\"\\s+\",names=['t','PR'])\n",
        "table_agg = pd.read_table(file_path_aggregate ,sep=\"\\s+\",names=['t','PR'])\n",
        "  \n",
        "data = table.to_numpy()\n",
        "data_agg = table_agg.to_numpy()\n",
        "\n",
        "data[:,0] = data[:,0] - data_agg[:,0].min()\n",
        "data_agg[:,0] = data_agg[:,0] - data_agg[:,0].min()\n",
        "\n",
        "data_agg[:,0].min()-data[:,0].min() / -86400\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf1Kpb2ZTxAk"
      },
      "source": [
        "def HeatmapAgg(start, stop):\n",
        "  window_start = start *86400                                                          # Frame start \n",
        "  window_stop = stop * 86400   # Frame end\n",
        "  \n",
        "  ind_agg = (data_agg[:,0] >= (window_start)) & (data_agg[:,0] < (window_stop)) \n",
        "  data_agg_test = data_agg[ind_agg]  \n",
        "  # print(data_agg_test[0])                                            # Separating data into smaller pieces\n",
        "\n",
        "  m = round((data_agg_test[:,0].max() - data_agg_test[:,0].min())/86400)\n",
        "\n",
        "  #day_data = np.zeros(17280)\n",
        "\n",
        "  for j in range(m):\n",
        "    day_data = np.zeros(17280)\n",
        "  \n",
        "    for i in range(17280):\n",
        "      id = (data_agg_test[:,0] >= (window_start) + (j*86400)+(i*5)) & (data_agg_test[:,0] < (window_start) + (j*86400)+((i+1)*5))\n",
        "      day_data[i] = np.mean(data_agg_test[id,1])\n",
        "\n",
        "    heatmap = np.transpose(day_data.reshape(24,720))\n",
        "    # print(heatmap)\n",
        "    plt.figure\n",
        "    plt.title('Aggregated data for day ' + str(start + j + 1))\n",
        "    plt.xlabel('Hours')\n",
        "    plt.ylabel('Seconds')\n",
        "    sns.heatmap(heatmap,cmap = 'Greys_r')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TmvjxCZGTJT"
      },
      "source": [
        "table_agg1 = pd.read_table(file_path_aggregate ,sep=\"\\s+\",names=['t','PR'])\n",
        "\n",
        "data1 = table1.to_numpy()\n",
        "data_agg1 = table_agg1.to_numpy()\n",
        "\n",
        "data1[:,0] = data1[:,0] - data_agg1[:,0].min()\n",
        "data_agg1[:,0] = data_agg1[:,0] - data_agg1[:,0].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jea0wCpvJYSc"
      },
      "source": [
        "def Heatmap_noappliance(start, stop):\n",
        "\n",
        "  window_start = start * 86400\n",
        "  window_stop = stop * 86400\n",
        "  ind_agg = (data_agg[:,0] >= (window_start)) & (data_agg[:,0] < (window_stop)) \n",
        "  ind = (data[:,0] >= (window_start)) & (data[:,0] < (window_stop)) \n",
        "\n",
        "  data_agg_test = data_agg[ind_agg]\n",
        "  #print(data_agg_test[0])\n",
        " \n",
        "  data_test = data[ind]\n",
        "  #print(data_test[0])\n",
        "\n",
        "\n",
        "  m = round((data_agg_test[:,0].max() - data_agg_test[:,0].min())/86400)\n",
        "\n",
        "  #day_data = np.zeros(17280)\n",
        "\n",
        "  for j in range(m):\n",
        "    day_data = np.zeros(17280)\n",
        "\n",
        "  \n",
        "    for i in range(17280):\n",
        "      idx_agg = (data_agg_test[:,0] >= (window_start) + (j*86400) + (i*5)) & (data_agg_test[:,0] < (window_start) + (j*86400)+((i+1)*5))\n",
        "      idx = (data_test[:,0] >= (window_start) +  (j*86400)+(i*5)) & (data_test[:,0] < (window_start) + (j*86400)+((i+1)*5))\n",
        "\n",
        "      if np.isnan(np.mean(data_test[idx,1])) == True:\n",
        "         day_data[i] = np.mean(data_agg_test[idx_agg,1])\n",
        "\n",
        "     #    print(data_agg_test[idx_agg,1])\n",
        "      else:\n",
        "        day_data[i] = np.mean(data_agg_test[idx_agg,1]) - np.mean(data_test[idx,1])\n",
        "        # print(np.mean(data_test[idx,1]))\n",
        "\n",
        "    heatmap = np.transpose(day_data.reshape(24,720))\n",
        "    # print(heatmap)\n",
        "\n",
        "    plt.figure\n",
        "    plt.title('Aggregated data for day ' + str(start + j + 1) + ' minus the ' + Appliance )\n",
        "    plt.xlabel('Hours')\n",
        "    plt.ylabel('Seconds')\n",
        "    sns.heatmap(heatmap,cmap = 'Greys_r')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al1d-LaTLQOz"
      },
      "source": [
        "HeatmapAgg(35,36)\n",
        "Heatmap_noappliance(40,41)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2MVHROgjUY2"
      },
      "source": [
        "# Reading files into dataframes\n",
        "table = pd.read_table(file_path,sep=\"\\s+\",names=['t','PR'])\n",
        "table_agg = pd.read_table(file_path_aggregate ,sep=\"\\s+\",names=['t','PR'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwQkr2lwyCD2"
      },
      "source": [
        "# Transfering data into numpy arrays\n",
        "data = table.to_numpy()\n",
        "data_agg = table_agg.to_numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKvQIXWcIxFZ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtPj_rYCnX20"
      },
      "source": [
        "# Statistical data of the appliance and aggregated data sets\n",
        "max_appliance = max(data[:,1])\n",
        "min_appliance = min(data[:,1])\n",
        "range_appliance = max_appliance - min_appliance\n",
        "\n",
        "max_agg = max(data_agg[:,1])\n",
        "min_agg = min(data_agg[:,1])\n",
        "range_agg = max_appliance - min_appliance\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3vn628k9llJ"
      },
      "source": [
        "# Printing statistical values\n",
        "\n",
        "print(max_appliance)\n",
        "print(min_appliance)\n",
        "print(range_appliance)\n",
        "\n",
        "print(max_agg)\n",
        "print(min_agg)\n",
        "print(range_agg)\n",
        "\n",
        "print(np.mean(data_agg[:,1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psb6KF11--_Z"
      },
      "source": [
        "# Finding the average and maximum time gap between data readings\n",
        "gap = []\n",
        "for i in range(len(data_agg[:,0])-1):\n",
        "  a = data_agg[i+1,0]-data_agg[i,0]\n",
        "  gap.append(a)\n",
        "\n",
        "print(max(gap))\n",
        "print(np.mean(gap))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uuVLNddytPj"
      },
      "source": [
        "# Recalibrating data to start from 0\n",
        "data[:,0] = data[:,0] - data[0,0]\n",
        "data_agg[:,0] = data_agg[:,0] - data_agg[0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YazqKmCNwJ7T"
      },
      "source": [
        "# An attempt to smooth data\n",
        "\n",
        "z_score = stats.zscore(data[:,1])\n",
        "ind = z_score < 3\n",
        "data = data[ind]\n",
        "\n",
        "z_score_agg = stats.zscore(data_agg[:,1])\n",
        "ind_agg = z_score_agg < 2\n",
        "data_agg = data_agg[ind_agg]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg7zgMYxImCI"
      },
      "source": [
        "# 1st Heatmap attempt \n",
        "\n",
        "n = 1\n",
        "secs = 60 * 60 * 24 * n\n",
        "total_time = data[-1,0] - data[0,0]\n",
        "m =  total_time / secs\n",
        "m = int(m)\n",
        "\n",
        "\n",
        "for i in range(4):\n",
        "  idx = (data[:,0] >= i*secs) & (data[:,0] < (i+1)*secs)\n",
        "  idx_agg = (data_agg[:,0] >= i*secs) & (data_agg[:,0] < (i+1)*secs)\n",
        "  plt.figure()\n",
        "  plt.plot(data[idx,0],data[idx,1])\n",
        "  plt.plot(data_agg[idx_agg,0],data_agg[idx_agg,1])\n",
        "  plt.ylim([-10,1000])\n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh5Q4_mdd3aZ"
      },
      "source": [
        "day = 60 * 60 * 24\n",
        "hour = 60 * 60\n",
        "minute = 60\n",
        "\n",
        "# Chosen time frame ########\n",
        "TimeFrame = 30 * day\n",
        "Window_Y = 60 * minute\n",
        "Window_X = 1 * day\n",
        "############################\n",
        "\n",
        "total_time = data[-1,0] - data[0,0]\n",
        "m =  total_time / TimeFrame\n",
        "m = int(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6-M91xl_f7-"
      },
      "source": [
        "X_bins = int(TimeFrame / Window_X)\n",
        "Y_bins = int(Window_X / Window_Y)\n",
        "\n",
        "for k in range(1):\n",
        "  matrix = np.zeros((Y_bins,X_bins))\n",
        "  for i in range(X_bins):\n",
        "    for j in range(Y_bins):\n",
        "      idx = (data_agg[:,0] >= (k*TimeFrame)+(i*Window_X)+(j*Window_Y) & (data_agg[:,0] < (k*TimeFrame)+(i*Window_X)+((j*+1)*Window_Y)))\n",
        "      val = np.mean(data_agg[idx,1])\n",
        "      matrix[j,i] = val\n",
        "  plt.imshow(matrix, cmap='hot', interpolation='nearest')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODFDjsE0LXHZ"
      },
      "source": [
        "window_start = 0\n",
        "window_stop = 1\n",
        "ind_agg = (data_agg[:,0] >= (window_start*86400)) & (data_agg[:,0] < (window_stop*86400)) \n",
        "#ind = (data[:,0] >= (window_start*86400)) & (data[:,0] < (window_stop*86400)) \n",
        "\n",
        "data_agg_test = data_agg[ind_agg]\n",
        "#data_test = data[ind]\n",
        "\n",
        "m = round(data_agg_test[-1,0]/86400)\n",
        "\n",
        "\n",
        "day_data = np.zeros(17280)\n",
        "\n",
        "for j in range(m):\n",
        "  day_data = np.zeros(17280)\n",
        "  print('yes')\n",
        "  \n",
        "  for i in range(17280):\n",
        "    id = (data_agg_test[:,0] >= (j*86400)+(i*5)) & (data_agg_test[:,0] < (j*86400)+((i+1)*5))\n",
        "    day_data[i] = np.mean(data_agg_test[id,1])\n",
        "\n",
        "  heatmap = np.transpose(day_data.reshape(24,720))\n",
        "  plt.figure\n",
        "  sns.heatmap(heatmap,cmap = 'RdYlGn')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U7kppdOjvTX"
      },
      "source": [
        "window_start = 0\n",
        "window_stop = 1\n",
        "ind_agg = (data_agg[:,0] >= (window_start*86400)) & (data_agg[:,0] < (window_stop*86400)) \n",
        "ind = (data[:,0] >= (window_start*86400)) & (data[:,0] < (window_stop*86400)) \n",
        "\n",
        "data_agg_test = data_agg[ind_agg]\n",
        "data_test = data[ind]\n",
        "\n",
        "m = round(data_agg_test[-1,0]/86400)\n",
        "\n",
        "\n",
        "day_data = np.zeros(17280)\n",
        "\n",
        "for j in range(m):\n",
        "  day_data = np.zeros(17280)\n",
        "  print('yes')\n",
        "  \n",
        "  for i in range(17280):\n",
        "    idx_agg = (data_agg_test[:,0] >= (j*86400)+(i*5)) & (data_agg_test[:,0] < (j*86400)+((i+1)*5))\n",
        "    idx = (data_test[:,0] >= (j*86400)+(i*5)) & (data_test[:,0] < (j*86400)+((i+1)*5))\n",
        "\n",
        "    day_data[i] = np.mean(data_agg_test[idx_agg,1]) - np.mean(data_test[idx,1])\n",
        "\n",
        "  heatmap = np.transpose(day_data.reshape(24,720))\n",
        "  plt.figure\n",
        "  sns.heatmap(heatmap,cmap = 'RdYlGn')\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IePy-tUYbAoX"
      },
      "source": [
        "# day_data.shape\n",
        "heatmap = np.transpose(day_data.reshape(24,720))\n",
        "day_data\n",
        "heatmap.shape\n",
        "print(day_data[0:10])\n",
        "print(heatmap[0:10,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPEFxVdKd626"
      },
      "source": [
        "plt.figure\n",
        "sns.heatmap(heatmap,cmap = 'RdYlGn')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}